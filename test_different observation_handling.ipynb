{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Jupyter setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "from sklearn.metrics import f1_score, accuracy_score, top_k_accuracy_score\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pd.set_option('display.max_columns', None)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fgvc.utils.datasets import TrainDataset\n",
    "from fgvc.utils.augmentations import test_transforms\n",
    "# from fgvc.utils.utils import timer, init_logger, , \n",
    "\n",
    "from fgvc.utils.utils import timer, init_logger, seed_everything, getModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = pd.read_csv(\"../../metadata/PlantCLEF2018_train_metadata.csv\")\n",
    "val_metadata = pd.read_csv(\"../../metadata/PlantCLEF2018_val_metadata.csv\")\n",
    "\n",
    "PlantCLEF2017_test = pd.read_csv(\"../../metadata/PlantCLEF2017_test_metadata.csv\")\n",
    "PlantCLEF2018_test = pd.read_csv(\"../../metadata/PlantCLEF2018_test_metadata.csv\")\n",
    "\n",
    "print(f'Number of samples in PlantCLEF2017_test: {len(PlantCLEF2017_test)}')\n",
    "print(f'Number of samples in PlantCLEF2018_test: {len(PlantCLEF2018_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metadata['image_path'] = val_metadata['image_path'].apply(lambda x: x.replace('../../../nahouby/Datasets/PlantCLEF/', '/local/nahouby/Datasets/PlantCLEF/'))\n",
    "val_metadata['image_path'] = val_metadata['image_path'].apply(lambda x: x.replace('../../nahouby/Datasets/PlantCLEF/', '/local/nahouby/Datasets/PlantCLEF/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust BATCH_SIZE and ACCUMULATION_STEPS to values that if multiplied results in 64 !!!!!1\n",
    "\n",
    "config = {\"augmentations\": 'light-random_crop',\n",
    "           \"optimizer\": 'SGD',\n",
    "           \"scheduler\": 'cyclic_cosine',\n",
    "           \"image_size\": (224, 224),\n",
    "           \"random_seed\": 777,\n",
    "           \"number_of_classes\": len(train_metadata['class_id'].unique()),\n",
    "           \"architecture\": 'tf_efficientnetv2_s_in21k',\n",
    "           \"batch_size\": 32,\n",
    "           \"accumulation_steps\": 4,\n",
    "           \"epochs\": 100,\n",
    "           \"learning_rate\": 0.01,\n",
    "           \"dataset\": 'PlantCLEF2018',\n",
    "           \"loss\": 'CrossEntropyLoss',\n",
    "           \"training_samples\": len(train_metadata),\n",
    "           \"valid_samples\": len(val_metadata),\n",
    "           \"workers\": 12,\n",
    "           }\n",
    "\n",
    "RUN_NAME = f\"{config['architecture']}-{config['optimizer']}-{config['scheduler']}-{config['augmentations']}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(config['random_seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "model = getModel(config['architecture'], config['number_of_classes'], pretrained=True)\n",
    "model_mean = list(model.default_cfg['mean'])\n",
    "model_std = list(model.default_cfg['std'])\n",
    "\n",
    "model.load_state_dict(torch.load('./tf_efficientnetv2_s_in21k-SGD-cyclic_cosine-light-random_crop-100E.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust BATCH_SIZE and ACCUMULATION_STEPS to values that if multiplied results in 64 !!!!!1\n",
    "\n",
    "crop_augmentations = test_transforms(data='center_crop', image_size=config['image_size'], mean=model_mean, std=model_std)    \n",
    "\n",
    "PlantCLEF2017_test_dataset_crop = TrainDataset(PlantCLEF2017_test, transform=crop_augmentations)\n",
    "PlantCLEF2018_test_dataset_crop = TrainDataset(PlantCLEF2018_test, transform=crop_augmentations)\n",
    "val_dataset = TrainDataset(val_metadata, transform=crop_augmentations)\n",
    "\n",
    "\n",
    "PlantCLEF2017_test_loader_crop = DataLoader(PlantCLEF2017_test_dataset_crop, \n",
    "                                               batch_size=config['batch_size'], \n",
    "                                               shuffle=False, \n",
    "                                               num_workers=config['workers'])\n",
    "\n",
    "PlantCLEF2018_test_loader_crop = DataLoader(PlantCLEF2018_test_dataset_crop, \n",
    "                                               batch_size=config['batch_size'], \n",
    "                                               shuffle=False, \n",
    "                                               num_workers=config['workers'])\n",
    "\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                                               batch_size=config['batch_size'], \n",
    "                                               shuffle=False, \n",
    "                                               num_workers=config['workers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f'Model Loaded and set to Eval mode.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fgvc.utils.performance import test_loop_develop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  PlantCLEF 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_2017 = test_loop_develop(PlantCLEF2017_test, PlantCLEF2017_test_loader_crop, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_2017 = test_loop_develop(PlantCLEF2017_test, PlantCLEF2017_test_loader_crop, model, device)\n",
    "print('Accuracy:', performance_2017['acc'])\n",
    "print('Obs. Accuracy (max logit):', performance_2017['max_logits_acc'])\n",
    "print('Obs. Accuracy (mean logits):', performance_2017['mean_logits_acc'])\n",
    "print('Obs. Accuracy (max softmax):', performance_2017['max_softmax_acc'])\n",
    "print('Obs. Accuracy (mean softmax):', performance_2017['mean_softmax_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PlantCLEF 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_2018 = test_loop_develop(PlantCLEF2018_test, PlantCLEF2018_test_loader_crop, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy:', performance_2018['acc'])\n",
    "print('Obs. Accuracy (max logit):', performance_2018['max_logits_acc'])\n",
    "print('Obs. Accuracy (mean logits):', performance_2018['mean_logits_acc'])\n",
    "print('Obs. Accuracy (max softmax):', performance_2018['max_softmax_acc'])\n",
    "print('Obs. Accuracy (mean softmax):', performance_2018['mean_softmax_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fgvc.utils.performance import test_loop_insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_val, val_metadata = test_loop_insights(val_metadata, val_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy:', performance_val['acc'])\n",
    "print('Obs. Accuracy (max logit):', performance_val['max_logits_acc'])\n",
    "print('Obs. Accuracy (mean logits):', performance_val['mean_logits_acc'])\n",
    "print('Obs. Accuracy (max softmax):', performance_val['max_softmax_acc'])\n",
    "print('Obs. Accuracy (mean softmax):', performance_val['mean_softmax_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metadata.fillna('unknown', inplace=True)\n",
    "val_metadata.Content.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(tmp.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_analysis(test_metadata, performance_threshold: int = 0.70, performance_step: int = 0.05):\n",
    "    class_tresholds = {}\n",
    "    classified_documents = 0\n",
    "    \n",
    "    for class_id in tqdm.tqdm(sorted(test_metadata.class_id.unique()), total=len(test_metadata.class_id.unique())):\n",
    "\n",
    "        for threshold in np.arange(0.0, 1.0, performance_step):\n",
    "\n",
    "            class_metadata = test_metadata[test_metadata.class_id == class_id]\n",
    "            tmp = class_metadata[class_metadata['max_softmax'] >= threshold]\n",
    "            if len(tmp) != 0:\n",
    "                vanilla_accuracy = accuracy_score(tmp['class_id'], tmp['preds'])\n",
    "\n",
    "                if performance_threshold <= vanilla_accuracy:\n",
    "                    class_tresholds[class_id] = threshold\n",
    "                    num_documents = len(tmp[tmp['max_softmax'] >= threshold])\n",
    "                    if len(class_metadata) != 0:\n",
    "                        doc_fraction = num_documents / len(class_metadata)\n",
    "                    else:\n",
    "                        doc_fraction = 0\n",
    "\n",
    "                    classified_documents += num_documents\n",
    "                    break                \n",
    "        else:\n",
    "            class_tresholds[class_id] = 1.0\n",
    "\n",
    "    return class_tresholds, classified_documents / len(test_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_tresholds, fraction = threshold_analysis(val_metadata, 0.8, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(class_tresholds.values(), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.zeros((len(PlantCLEF2017_test)))\n",
    "preds_raw = []\n",
    "wrong_paths = []\n",
    "\n",
    "for i, (images, _, _) in tqdm.tqdm(enumerate(PlantCLEF2017_test_loader_crop), total=len(PlantCLEF2017_test_loader_crop)):\n",
    "\n",
    "    images = images.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_preds = model(images)\n",
    "    preds[i * len(images): (i+1) * len(images)] = y_preds.argmax(1).to('cpu').numpy()\n",
    "    preds_raw.extend(y_preds.to('cpu').numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlantCLEF2017_test['logits'] = preds_raw\n",
    "PlantCLEF2017_test['preds'] = preds\n",
    "PlantCLEF2017_test['softmax'] = [softmax(row) for row in PlantCLEF2017_test['logits']]\n",
    "PlantCLEF2017_test['max_softmax'] = [np.max(row) for row in PlantCLEF2017_test['softmax']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(PlantCLEF2017_test['class_id'], PlantCLEF2017_test['preds'].astype('int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlantCLEF2017_test['observation_mean'] = None\n",
    "\n",
    "ObservationIds = PlantCLEF2017_test.ObservationId.unique()\n",
    "\n",
    "for obs_id in tqdm.tqdm(ObservationIds, total=len(ObservationIds)):\n",
    "    obs_images = PlantCLEF2017_test[PlantCLEF2017_test['ObservationId'] == obs_id].copy()\n",
    "    obs_images['softmax'] = obs_images.apply(lambda row: row.softmax if row.max_softmax >= class_tresholds[row.preds] else np.ones(config['number_of_classes']) / config['number_of_classes'], axis=1)\n",
    "    max_index =  np.argmax(sum(obs_images['softmax']))\n",
    "    for index, pred in obs_images.iterrows():\n",
    "        PlantCLEF2017_test.at[index, 'observation_mean'] = max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata_obs = PlantCLEF2017_test.drop_duplicates(subset=['ObservationId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_metadata_obs['class_id'], test_metadata_obs['observation_mean'].astype('int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(PlantCLEF2017_test['class_id'], PlantCLEF2017_test['preds'].astype('int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlantCLEF2017_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(selected_predictions) / len(val_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_accuracy = accuracy_score(selected_predictions['class_id'], selected_predictions['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_analysis_logits(test_metadata, performance_threshold: int = 0.70, num_steps = 20):\n",
    "    class_tresholds = {}\n",
    "    classified_documents = 0\n",
    "    \n",
    "    min_logit = min(test_metadata['max_logits']) - 1\n",
    "    max_logit = max(test_metadata['max_logits']) + 1\n",
    "    \n",
    "    performance_step = (max_logit - min_logit) / num_steps\n",
    "    \n",
    "    for class_id in sorted(test_metadata.class_id.unique()):\n",
    "\n",
    "        for threshold in np.arange(min_logit, max_logit, performance_step):\n",
    "\n",
    "            class_metadata = test_metadata[test_metadata.class_id == class_id]\n",
    "            tmp = class_metadata[class_metadata['max_logits'] >= threshold]\n",
    "            if len(tmp) != 0:\n",
    "                vanilla_accuracy = accuracy_score(tmp['class_id'], tmp['preds'])\n",
    "\n",
    "                if performance_threshold <= vanilla_accuracy:\n",
    "                    class_tresholds[class_id] = threshold\n",
    "                    num_documents = len(tmp[tmp['max_logits'] >= threshold])\n",
    "                    if len(class_metadata) != 0:\n",
    "                        doc_fraction = num_documents / len(class_metadata)\n",
    "                    else:\n",
    "                        doc_fraction = 0\n",
    "\n",
    "                    classified_documents += num_documents\n",
    "\n",
    "                    #print(f'Threshold for class {class_id_2_doc_type[class_id]} is {round(threshold * 100,2)}. Achieved accuracy of {vanilla_accuracy} for {round(doc_fraction * 100,2)} of files.')\n",
    "                    break                \n",
    "        else:\n",
    "            class_tresholds[class_id] = 1.0\n",
    "            #print(f'No threshold for class {class_id_2_doc_type[class_id]}.')\n",
    "\n",
    "    return class_tresholds, classified_documents / len(test_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_tresholds, fraction = threshold_analysis_logits(val_metadata, 0.7, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(class_tresholds.values(), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_fractions = []\n",
    "\n",
    "for class_id in tqdm.tqdm(sorted(val_metadata.class_id.unique()), total=len(val_metadata.class_id.unique())):\n",
    "\n",
    "    class_metadata = val_metadata[val_metadata.class_id == class_id]\n",
    "    tmp = class_metadata[class_metadata['max_logits'] >= class_tresholds[class_id]]\n",
    "    class_fractions.append(tmp)\n",
    "\n",
    "selected_predictions = pd.concat(class_fractions).reset_index().drop(columns=['index', 'Unnamed: 0'])\n",
    "vanilla_accuracy = accuracy_score(selected_predictions['class_id'], selected_predictions['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_tresholds, fraction = threshold_analysis(val_metadata, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(class_tresholds.values(), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_step = 0.1\n",
    "\n",
    "fractions = []\n",
    "accuracies = []\n",
    "\n",
    "for performance_threshold in tqdm.tqdm(np.arange(0.0, 1.0, performance_step), total=1/performance_step):\n",
    "\n",
    "    class_tresholds, fraction = threshold_analysis(val_metadata, performance_threshold, performance_step)\n",
    "    \n",
    "    class_fractions = []\n",
    "\n",
    "    for class_id in sorted(val_metadata.class_id.unique()):\n",
    "\n",
    "        class_metadata = val_metadata[val_metadata.class_id == class_id]\n",
    "        tmp = class_metadata[class_metadata['max_probability'] >= class_tresholds[class_id]]\n",
    "        class_fractions.append(tmp)\n",
    "\n",
    "    selected_predictions = pd.concat(class_fractions).reset_index().drop(columns=['index', 'Unnamed: 0'])\n",
    "    vanilla_accuracy = accuracy_score(selected_predictions['class_id'], selected_predictions['preds'])\n",
    "    \n",
    "    fractions.append(fraction)\n",
    "    accuracies.append(vanilla_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accuracies, fractions, '-', linewidth=1, markersize=2)\n",
    "plt.ylabel('Fraction of Classified documents')\n",
    "plt.xlabel('Overall Accuracy.')\n",
    "plt.xlim(0.55, 1.0)\n",
    "plt.ylim(0.4, 1.0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('accuracy_to_num.pdf', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

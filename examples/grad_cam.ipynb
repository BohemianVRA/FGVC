{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports & definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# imports\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import timm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from fgvc.special.grad_cam import GradCamTimm, plot_grad_cam\n",
    "from fgvc.utils.utils import set_cuda_device\n",
    "\n",
    "# constants\n",
    "IMG_URL = \"https://cdn.pixabay.com/photo/2015/11/16/22/14/cat-1046544_960_720.jpg\"\n",
    "IMG_SIZE = 224\n",
    "\n",
    "device = set_cuda_device(\"0\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Input image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocess_image(img_pil, img_size):\n",
    "    # resize the image\n",
    "    # if img.size[0] > img.size[1]:\n",
    "    #     im_newsize = (IMG_SIZE, int(IMG_SIZE / img.size[0] * img.size[1]))\n",
    "    # else:\n",
    "    #     im_newsize = (int(IMG_SIZE / img.size[1] * img.size[0]), IMG_SIZE)\n",
    "    img_np = np.asarray(img_pil.resize(img_size), dtype=np.uint8)\n",
    "\n",
    "    # create a batch\n",
    "    img_torch = torch.from_numpy(img_np).permute(2, 0, 1).float() / 255.0  # (H, W, C) to (C, H, W)\n",
    "\n",
    "    return img_np, img_torch\n",
    "\n",
    "\n",
    "# Get and prepare an image\n",
    "img_pil = Image.open(requests.get(IMG_URL, stream=True).raw).convert(\"RGB\")\n",
    "img_np, img_torch = preprocess_image(img_pil, img_size=(IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "# show the image\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_np)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model attention\n",
    "\n",
    "### 1. Select the last convolutional layer automatically (default)\n",
    "\n",
    "- target_layer of GradCamTimm must be None:\n",
    "\n",
    "        grad_cam = GradCamTimm(<timm model>, target_layer=None)  # or just: GradCamTimm(<timm model>)\n",
    "\n",
    "- then you need to call the instance of GradCamTimm to receive the attentions for your image\n",
    "- additionally, you can pass the target_cls as number in range <i>[0, N - 1]</i>, where N is number of classes,\n",
    "  to get attentions. Argmax of the classification head is taken in default\n",
    "\n",
    "        attn = grad_cam(<single image>, target_cls=<None (default) or number in range [0, N - 1]>)\n",
    "\n",
    "- finally, you can visualize the attentions\n",
    "    1. as heatmap with a scale using\n",
    "       <code>grad_cam.visualize_as_heatmap(&lt;subplot ax&gt;, attn)</code>\n",
    "    2. as attention to partial parts of the image using\n",
    "       <code>grad_cam.visualize_as_image(&lt;subplot ax&gt;, attn, &lt;single image&gt;)</code>\n",
    "\n",
    "- besides, you can get:\n",
    "    1. the original features that has been weighted with attention\n",
    "       <code>feats = grad_cam.get_features()</code>\n",
    "    2. gradients that was used for weighting the features\n",
    "       <code>grads = grad_cam.get_gradients()</code>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create a model and Grad-CAM instance\n",
    "net = timm.create_model(\"resnet50\", pretrained=True)\n",
    "grad_cam = GradCamTimm(net, device=device)\n",
    "\n",
    "# get the attentions\n",
    "attn, (feats, grads) = grad_cam(img_torch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_grad_cam(img_torch, model=net, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Select the target layer manually\n",
    "\n",
    "- target_layer of GradCamTimm must not be None:\n",
    "\n",
    "        grad_cam = GradCamTimm(<timm model>, target_layer=<required layer>)\n",
    "\n",
    "- you can also set the target_layer using:\n",
    "\n",
    "        grad_cam.set_target_layer(\"<target layer>\")\n",
    "\n",
    "- you can list possible layers typing:\n",
    "\n",
    "        pos_targ_layers = grad_cam.get_possible_target_layers()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pos_targ_layers = grad_cam.get_possible_target_layers()\n",
    "print(\"Possible target layers for your model:\")\n",
    "[print(f\"- {l}\") for l in pos_targ_layers];"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_grad_cam(img_torch, model=net, device=device, target_layer=\"layer4\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use Different Architectures"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, img_torch_224 = preprocess_image(img_pil, img_size=(224, 224))\n",
    "_, img_torch_384 = preprocess_image(img_pil, img_size=(384, 384))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ResNet-50"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net = timm.create_model(\"resnet50\", pretrained=True)\n",
    "plot_grad_cam(img_torch_224, model=net, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net = timm.create_model(\"resnet50\", pretrained=True)\n",
    "plot_grad_cam(img_torch_384, model=net, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ViT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net = timm.create_model(\"vit_base_patch16_384\", pretrained=True)\n",
    "plot_grad_cam(img_torch_384, model=net, device=device, target_layer=\"blocks\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net = timm.create_model(\"vit_base_patch8_224\", pretrained=True)\n",
    "plot_grad_cam(img_torch_224, model=net, device=device, target_layer=\"blocks\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SwinT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net = timm.create_model(\"swin_large_patch4_window12_384\", pretrained=True)\n",
    "plot_grad_cam(img_torch_384, model=net, device=device, target_layer=\"layers\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net = timm.create_model(\"swin_base_patch4_window7_224_in22k\", pretrained=True)\n",
    "plot_grad_cam(img_torch_224, model=net, device=device, target_layer=\"layers\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Different Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, img_torch_224 = preprocess_image(img_pil, img_size=(224, 224))\n",
    "_, img_torch_384 = preprocess_image(img_pil, img_size=(384, 384))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = timm.create_model(\"resnet50\", pretrained=True)\n",
    "plot_grad_cam(img_torch_224, model=net, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = timm.create_model(\"resnet50\", pretrained=True)\n",
    "plot_grad_cam(img_torch_384, model=net, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = timm.create_model(\"vit_base_patch16_384\", pretrained=True)\n",
    "plot_grad_cam(img_torch_384, model=net, device=device, target_layer=\"blocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = timm.create_model(\"vit_base_patch8_224\", pretrained=True)\n",
    "plot_grad_cam(img_torch_224, model=net, device=device, target_layer=\"blocks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SwinT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = timm.create_model(\"swin_large_patch4_window12_384\", pretrained=True)\n",
    "plot_grad_cam(img_torch_384, model=net, device=device, target_layer=\"layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = timm.create_model(\"swin_base_patch4_window7_224_in22k\", pretrained=True)\n",
    "plot_grad_cam(img_torch_224, model=net, device=device, target_layer=\"layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Imports & definitions\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# imports\n",
    "import os\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import timm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from fgvc.special.grad_cam import GradCamTimm, plot_grad_cam\n",
    "\n",
    "# constants\n",
    "IMG_URL = \"https://cdn.pixabay.com/photo/2015/11/16/22/14/cat-1046544_960_720.jpg\"\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# settings\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Input image\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get and prepare an image\n",
    "img = Image.open(requests.get(IMG_URL, stream=True).raw).convert(\"RGB\")\n",
    "# img = Image.open(IMG).convert(\"RGB\")\n",
    "\n",
    "# resize the image\n",
    "if img.size[0] > img.size[1]:\n",
    "    im_newsize = (IMG_SIZE, int(IMG_SIZE / img.size[0] * img.size[1]))\n",
    "else:\n",
    "    im_newsize = (int(IMG_SIZE / img.size[1] * img.size[0]), IMG_SIZE)\n",
    "img = img.resize(im_newsize)\n",
    "np_img = np.array(img, dtype=np.uint8)\n",
    "\n",
    "# create a batch\n",
    "tensor_img = torch.from_numpy(np_img).permute(2, 0, 1).float() / 255.0  # (H, W, C) to (C, H, W)\n",
    "\n",
    "# show the image\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(np_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Model attention\n",
    "---------------\n",
    "\n",
    "#### 1. Select the last convolutional layer automatically (default)\n",
    "\n",
    "- target_layer of GradCamTimm must be None:\n",
    "\n",
    "        grad_cam = GradCamTimm(<timm model>, target_layer=None)  # or just: GradCamTimm(<timm model>)\n",
    "\n",
    "- then you need to call the instance of GradCamTimm to receive the attentions for your image\n",
    "- additionally, you can pass the target_cls as number in range <i>[0, N - 1]</i>, where N is number of classes,\n",
    "  to get attentions. Argmax of the classification head is taken in default\n",
    "\n",
    "        attn = grad_cam(<single image>, target_cls=<None (default) or number in range [0, N - 1]>)\n",
    "\n",
    "- finally, you can visualize the attentions\n",
    "    1. as heatmap with a scale using\n",
    "       <code>grad_cam.visualize_as_heatmap(&lt;subplot ax&gt;, attn)</code>\n",
    "    2. as attention to partial parts of the image using\n",
    "       <code>grad_cam.visualize_as_image(&lt;subplot ax&gt;, attn, &lt;single image&gt;)</code>\n",
    "\n",
    "- besides, you can get:\n",
    "    1. the original features that has been weighted with attention\n",
    "       <code>feats = grad_cam.get_features()</code>\n",
    "    2. gradients that was used for weighting the features\n",
    "       <code>grads = grad_cam.get_gradients()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create a model and Grad-CAM instance\n",
    "net = timm.create_model(\"resnet50\", pretrained=True)\n",
    "grad_cam = GradCamTimm(net, device=device)\n",
    "\n",
    "# get the attentions\n",
    "attn, (feats, grads) = grad_cam(tensor_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_grad_cam(tensor_img, model=net, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 2. Select the target layer manually\n",
    "\n",
    "- target_layer of GradCamTimm must not be None:\n",
    "\n",
    "        grad_cam = GradCamTimm(<timm model>, target_layer=<required layer>)\n",
    "\n",
    "- you can also set the target_layer using:\n",
    "\n",
    "        grad_cam.set_target_layer(\"<target layer>\")\n",
    "\n",
    "- you can list possible layers typing:\n",
    "\n",
    "        pos_targ_layers = grad_cam.get_possible_target_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pos_targ_layers = grad_cam.get_possible_target_layers()\n",
    "print(\"Possible target layers for your model:\")\n",
    "[print(f\"- {l}\") for l in pos_targ_layers];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_grad_cam(tensor_img, model=net, device=device, target_layer=\"layer2\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
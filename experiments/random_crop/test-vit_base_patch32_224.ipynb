{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Jupyter setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "from sklearn.metrics import f1_score, accuracy_score, top_k_accuracy_score\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pd.set_option('display.max_columns', None)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fgvc.utils.datasets import TrainDataset\n",
    "from fgvc.utils.augmentations import test_transforms\n",
    "# from fgvc.utils.utils import timer, init_logger, , \n",
    "\n",
    "from fgvc.utils.utils import timer, init_logger, seed_everything, getModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = pd.read_csv(\"../../metadata/PlantCLEF2018_train_metadata.csv\")\n",
    "val_metadata = pd.read_csv(\"../../metadata/PlantCLEF2018_val_metadata.csv\")\n",
    "\n",
    "\n",
    "PlantCLEF2017_test = pd.read_csv(\"../../metadata/PlantCLEF2017_test_metadata.csv\")\n",
    "PlantCLEF2018_test = pd.read_csv(\"../../metadata/PlantCLEF2018_test_metadata.csv\")\n",
    "\n",
    "\n",
    "expert_subset = pd.read_csv(\"../../metadata/MediaId_ObservationId_ManVsMachineSubPart_ExpertCLEF2018.csv\", sep=';', names=['MediaId', 'ObservationId'])\n",
    "expert_subset = PlantCLEF2018_test[PlantCLEF2018_test['MediaId'].isin(expert_subset.MediaId)]\n",
    "\n",
    "print(f'Number of samples in PlantCLEF2017_test: {len(PlantCLEF2017_test)}')\n",
    "print(f'Number of samples in PlantCLEF2018_test: {len(PlantCLEF2018_test)}')\n",
    "print(f'Number of samples in PlantCLEF2018_expert_test: {len(expert_subset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlantCLEF2017_test['image_path'] = PlantCLEF2017_test['image_path'].apply(lambda x: x.replace('/local/nahouby/Datasets/PlantCLEF/', '/Data-10T/PlantCLEF/'))\n",
    "\n",
    "PlantCLEF2018_test['image_path'] = PlantCLEF2018_test['image_path'].apply(lambda x: x.replace('/local/nahouby/Datasets/PlantCLEF/', '/Data-10T/PlantCLEF/'))\n",
    "\n",
    "expert_subset['image_path'] = expert_subset['image_path'].apply(lambda x: x.replace('/local/nahouby/Datasets/PlantCLEF/', '/Data-10T/PlantCLEF/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust BATCH_SIZE and ACCUMULATION_STEPS to values that if multiplied results in 64 !!!!!1\n",
    "\n",
    "config = {\"augmentations\": 'light-random_crop',\n",
    "           \"optimizer\": 'SGD',\n",
    "           \"scheduler\": 'cyclic_cosine',\n",
    "           \"image_size\": (224, 224),\n",
    "           \"random_seed\": 777,\n",
    "           \"number_of_classes\": len(train_metadata['class_id'].unique()),\n",
    "           \"architecture\": 'vit_base_patch32_224',\n",
    "           \"batch_size\": 32,\n",
    "           \"accumulation_steps\": 4,\n",
    "           \"epochs\": 100,\n",
    "           \"learning_rate\": 0.01,\n",
    "           \"dataset\": 'PlantCLEF2018',\n",
    "           \"loss\": 'CrossEntropyLoss',\n",
    "           \"training_samples\": len(train_metadata),\n",
    "           \"valid_samples\": len(val_metadata),\n",
    "           \"workers\": 12,\n",
    "           }\n",
    "\n",
    "RUN_NAME = f\"{config['architecture']}-{config['optimizer']}-{config['scheduler']}-{config['augmentations']}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(config['random_seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "model = getModel(config['architecture'], config['number_of_classes'], pretrained=True)\n",
    "model_mean = list(model.default_cfg['mean'])\n",
    "model_std = list(model.default_cfg['std'])\n",
    "\n",
    "model.load_state_dict(torch.load('./vit_base_patch32_224-SGD-cyclic_cosine-light-random_crop-100E.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust BATCH_SIZE and ACCUMULATION_STEPS to values that if multiplied results in 64 !!!!!1\n",
    "\n",
    "vanilla_augmentations = test_transforms(data='vanilla', image_size=config['image_size'], mean=model_mean, std=model_std)    \n",
    "crop_augmentations = test_transforms(data='center_crop', image_size=config['image_size'], mean=model_mean, std=model_std)    \n",
    "\n",
    "PlantCLEF2017_test_dataset_vanilla = TrainDataset(PlantCLEF2017_test, transform=vanilla_augmentations)\n",
    "PlantCLEF2017_test_dataset_crop = TrainDataset(PlantCLEF2017_test, transform=crop_augmentations)\n",
    "\n",
    "PlantCLEF2018_test_dataset_vanilla = TrainDataset(PlantCLEF2018_test, transform=vanilla_augmentations)\n",
    "PlantCLEF2018_test_dataset_crop = TrainDataset(PlantCLEF2018_test, transform=crop_augmentations)\n",
    "\n",
    "expert_test_dataset_vanilla = TrainDataset(expert_subset, transform=vanilla_augmentations)\n",
    "expert_test_dataset_crop = TrainDataset(expert_subset, transform=crop_augmentations)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "PlantCLEF2017_test_loader_vanilla = DataLoader(PlantCLEF2017_test_dataset_vanilla, \n",
    "                                               batch_size=config['batch_size'], \n",
    "                                               shuffle=False, \n",
    "                                               num_workers=config['workers'])\n",
    "\n",
    "PlantCLEF2017_test_loader_crop = DataLoader(PlantCLEF2017_test_dataset_crop, \n",
    "                                               batch_size=config['batch_size'], \n",
    "                                               shuffle=False, \n",
    "                                               num_workers=config['workers'])\n",
    "\n",
    "\n",
    "\n",
    "PlantCLEF2018_test_loader_vanilla = DataLoader(PlantCLEF2018_test_dataset_vanilla, \n",
    "                                               batch_size=config['batch_size'], \n",
    "                                               shuffle=False, \n",
    "                                               num_workers=config['workers'])\n",
    "\n",
    "PlantCLEF2018_test_loader_crop = DataLoader(PlantCLEF2018_test_dataset_crop, \n",
    "                                               batch_size=config['batch_size'], \n",
    "                                               shuffle=False, \n",
    "                                               num_workers=config['workers'])\n",
    "\n",
    "\n",
    "expert_test_loader_vanilla = DataLoader(expert_test_dataset_vanilla, \n",
    "                                               batch_size=config['batch_size'], \n",
    "                                               shuffle=False, \n",
    "                                               num_workers=config['workers'])\n",
    "\n",
    "expert_test_loader_crop = DataLoader(expert_test_dataset_crop, \n",
    "                                               batch_size=config['batch_size'], \n",
    "                                               shuffle=False, \n",
    "                                               num_workers=config['workers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f'Model Loaded and set to Eval mode.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fgvc.utils.performance import test_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  PlantCLEF 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_accuracy, vanilla_max_logit_obs_acc, vanilla_mean_softmax_obs_acc = test_loop(PlantCLEF2017_test, PlantCLEF2017_test_loader_vanilla, model, device)\n",
    "crop_accuracy, crop_max_logit_obs_acc, crop_mean_softmax_obs_acc = test_loop(PlantCLEF2017_test, PlantCLEF2017_test_loader_crop, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Vanilla Accuracy:', np.round(vanilla_accuracy * 100, 2))\n",
    "print('Vanilla Obs. Accuracy (max logit):', np.round(vanilla_max_logit_obs_acc * 100, 2))\n",
    "print('Vanila Obs. Accuracy (mean softmax):', np.round(vanilla_mean_softmax_obs_acc * 100, 2))\n",
    "print('------------------------------------')\n",
    "print('Crop Accuracy:', np.round(crop_accuracy * 100, 2))\n",
    "print('Crop Obs. Accuracy (max logit):', np.round(crop_max_logit_obs_acc * 100, 2))\n",
    "print('Crop Obs. Accuracy (mean softmax):', np.round(crop_mean_softmax_obs_acc * 100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PlantCLEF 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_accuracy, vanilla_max_logit_obs_acc, vanilla_mean_softmax_obs_acc = test_loop(PlantCLEF2018_test, PlantCLEF2018_test_loader_vanilla, model, device)\n",
    "crop_accuracy, crop_max_logit_obs_acc, crop_mean_softmax_obs_acc = test_loop(PlantCLEF2018_test, PlantCLEF2018_test_loader_crop, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Vanilla Accuracy:', np.round(vanilla_accuracy * 100, 2))\n",
    "print('Vanilla Obs. Accuracy (max logit):', np.round(vanilla_max_logit_obs_acc * 100, 2))\n",
    "print('Vanila Obs. Accuracy (mean softmax):', np.round(vanilla_mean_softmax_obs_acc * 100, 2))\n",
    "print('------------------------------------')\n",
    "print('Crop Accuracy:', np.round(crop_accuracy * 100, 2))\n",
    "print('Crop Obs. Accuracy (max logit):', np.round(crop_max_logit_obs_acc * 100, 2))\n",
    "print('Crop Obs. Accuracy (mean softmax):', np.round(crop_mean_softmax_obs_acc * 100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PlantCLEF 2018 - Experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_accuracy, vanilla_max_logit_obs_acc, vanilla_mean_softmax_obs_acc = test_loop(expert_subset, expert_test_loader_vanilla, model, device)\n",
    "crop_accuracy, crop_max_logit_obs_acc, crop_mean_softmax_obs_acc = test_loop(expert_subset, expert_test_loader_crop, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Vanilla Accuracy:', np.round(vanilla_accuracy * 100, 2))\n",
    "print('Vanilla Obs. Accuracy (max logit):', np.round(vanilla_max_logit_obs_acc * 100, 2))\n",
    "print('Vanila Obs. Accuracy (mean softmax):', np.round(vanilla_mean_softmax_obs_acc * 100, 2))\n",
    "print('------------------------------------')\n",
    "print('Crop Accuracy:', np.round(crop_accuracy * 100, 2))\n",
    "print('Crop Obs. Accuracy (max logit):', np.round(crop_max_logit_obs_acc * 100, 2))\n",
    "print('Crop Obs. Accuracy (mean softmax):', np.round(crop_mean_softmax_obs_acc * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def max_logits_performance(test_metadata):\n",
    "    \n",
    "    test_metadata['max_logits'] = [np.max(row) for row in test_metadata['logits']]\n",
    "    test_metadata['observation_max'] = None\n",
    "\n",
    "    ObservationIds = test_metadata.ObservationId.unique()\n",
    "\n",
    "    for obs_id in ObservationIds:\n",
    "        obs_images = test_metadata[test_metadata['ObservationId'] == obs_id]\n",
    "        max_index =  obs_images.index[np.argmax(np.array(obs_images['max_logits']))]\n",
    "        for index, pred in obs_images.iterrows():\n",
    "            test_metadata.at[index, 'observation_max'] = test_metadata['preds'][max_index]\n",
    "    \n",
    "    test_metadata_obs = test_metadata.drop_duplicates(subset=['ObservationId'])\n",
    "    max_logits_accuracy = accuracy_score(test_metadata_obs['class_id'], test_metadata_obs['observation_max'].astype('int32'))\n",
    "    \n",
    "    return max_logits_accuracy\n",
    "    \n",
    "    \n",
    "def mean_softmax_performance(test_metadata):\n",
    "    \n",
    "    test_metadata['observation_mean'] = None\n",
    "\n",
    "    ObservationIds = test_metadata.ObservationId.unique()\n",
    "\n",
    "    for obs_id in ObservationIds:\n",
    "        obs_images = test_metadata[test_metadata['ObservationId'] == obs_id]\n",
    "\n",
    "        max_index =  np.argmax(sum(obs_images['logits']))\n",
    "        for index, pred in obs_images.iterrows():\n",
    "            test_metadata.at[index, 'observation_mean'] = max_index\n",
    "    \n",
    "    test_metadata_obs = test_metadata.drop_duplicates(subset=['ObservationId'])\n",
    "    mean_softmax_accuracy = accuracy_score(test_metadata_obs['class_id'], test_metadata_obs['observation_mean'].astype('int32'))\n",
    "    \n",
    "    return mean_softmax_accuracy\n",
    "    \n",
    "    \n",
    "def observation_performance(test_metadata):\n",
    "    \n",
    "    max_logits_accuracy = max_logits_performance(test_metadata)\n",
    "    mean_softmax_accuracy = mean_softmax_performance(test_metadata)\n",
    "    \n",
    "    return max_logits_accuracy, mean_softmax_accuracy\n",
    "\n",
    "\n",
    "def test_loop(test_metadata, test_loader, model, device):\n",
    "    \n",
    "    preds = np.zeros((len(test_metadata)))\n",
    "    preds_raw = []\n",
    "    wrong_paths = []\n",
    "\n",
    "    for i, (images, _, _) in tqdm.tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "\n",
    "        images = images.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(images)\n",
    "        preds[i * len(images): (i+1) * len(images)] = y_preds.argmax(1).to('cpu').numpy()\n",
    "        preds_raw.extend(y_preds.to('cpu').numpy())\n",
    "\n",
    "    \n",
    "    test_metadata['logits'] = preds_raw\n",
    "    test_metadata['preds'] = preds\n",
    "\n",
    "    \n",
    "    accuracy = accuracy_score(test_metadata['class_id'], test_metadata['preds'])\n",
    "    \n",
    "    max_logit_obs_acc, mean_softmax_obs_acc = observation_performance(test_metadata)\n",
    "    \n",
    "    return accuracy, max_logit_obs_acc, mean_softmax_obs_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metadata['image_path'] = val_metadata['image_path'].apply(lambda x: x.replace('../../../nahouby/Datasets/PlantCLEF/', '/Data-10T/PlantCLEF/'))\n",
    "val_metadata['image_path'] = val_metadata['image_path'].apply(lambda x: x.replace('../../nahouby/Datasets/PlantCLEF/', '/Data-10T/PlantCLEF/'))\n",
    "\n",
    "val_dataset = TrainDataset(val_metadata, transform=vanilla_augmentations)\n",
    "\n",
    "\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                                               batch_size=config['batch_size'], \n",
    "                                               shuffle=False, \n",
    "                                               num_workers=config['workers'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.zeros((len(val_metadata)))\n",
    "preds_raw = []\n",
    "wrong_paths = []\n",
    "\n",
    "for i, (images, _, _) in tqdm.tqdm(enumerate(val_loader), total=len(val_loader)):\n",
    "\n",
    "    images = images.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_preds = model(images)\n",
    "    preds[i * len(images): (i+1) * len(images)] = y_preds.argmax(1).to('cpu').numpy()\n",
    "    preds_raw.extend(y_preds.to('cpu').numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metadata['logits'] = preds_raw\n",
    "val_metadata['preds'] = preds\n",
    "val_metadata['max_probability'] = [np.max(softmax(row)) for row in val_metadata['logits']]\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(val_metadata['class_id'], val_metadata['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metadata['max_probability'] = [np.max(softmax(row)) for row in val_metadata['logits']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metadata['max_probability'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_analysis(test_metadata, performance_threshold: int = 0.50, performance_step: int = 0.10):\n",
    "    class_tresholds = {}\n",
    "    classified_documents = 0\n",
    "    for class_id in sorted(test_metadata.class_id.unique()):\n",
    "\n",
    "        for threshold in np.arange(0.0, 1.0, performance_step):\n",
    "\n",
    "            class_metadata = test_metadata[test_metadata.class_id == class_id]\n",
    "            tmp = class_metadata[class_metadata['max_probability'] >= threshold]\n",
    "            if len(tmp) != 0:\n",
    "                vanilla_accuracy = accuracy_score(tmp['class_id'], tmp['preds'])\n",
    "\n",
    "                if performance_threshold <= vanilla_accuracy:\n",
    "                    class_tresholds[class_id] = threshold\n",
    "                    num_documents = len(tmp[tmp['max_probability'] >= threshold])\n",
    "                    if len(class_metadata) != 0:\n",
    "                        doc_fraction = num_documents / len(class_metadata)\n",
    "                    else:\n",
    "                        doc_fraction = 0\n",
    "\n",
    "                    classified_documents += num_documents\n",
    "\n",
    "                    #print(f'Threshold for class {class_id_2_doc_type[class_id]} is {round(threshold * 100,2)}. Achieved accuracy of {vanilla_accuracy} for {round(doc_fraction * 100,2)} of files.')\n",
    "                    break                \n",
    "        else:\n",
    "            class_tresholds[class_id] = 1.0\n",
    "            #print(f'No threshold for class {class_id_2_doc_type[class_id]}.')\n",
    "\n",
    "    return class_tresholds, classified_documents / len(test_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_tresholds, fraction = threshold_analysis(val_metadata, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(class_tresholds.values(), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_step = 0.1\n",
    "\n",
    "fractions = []\n",
    "accuracies = []\n",
    "\n",
    "for performance_threshold in tqdm.tqdm(np.arange(0.0, 1.0, performance_step), total=1/performance_step):\n",
    "\n",
    "    class_tresholds, fraction = threshold_analysis(val_metadata, performance_threshold, performance_step)\n",
    "    \n",
    "    class_fractions = []\n",
    "\n",
    "    for class_id in sorted(val_metadata.class_id.unique()):\n",
    "\n",
    "        class_metadata = val_metadata[val_metadata.class_id == class_id]\n",
    "        tmp = class_metadata[class_metadata['max_probability'] >= class_tresholds[class_id]]\n",
    "        class_fractions.append(tmp)\n",
    "\n",
    "    selected_predictions = pd.concat(class_fractions).reset_index().drop(columns=['index', 'Unnamed: 0'])\n",
    "    vanilla_accuracy = accuracy_score(selected_predictions['class_id'], selected_predictions['preds'])\n",
    "    \n",
    "    fractions.append(fraction)\n",
    "    accuracies.append(vanilla_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accuracies, fractions, '-', linewidth=1, markersize=2)\n",
    "plt.ylabel('Fraction of Classified documents')\n",
    "plt.xlabel('Overall Accuracy.')\n",
    "plt.xlim(0.55, 1.0)\n",
    "plt.ylim(0.4, 1.0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('accuracy_to_num.pdf', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
